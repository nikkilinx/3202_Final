{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: (8,)\n",
      "Number of actions: 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "env_name = 'LunarLander-v2'\n",
    "# env_name = 'CarRacing-v0'\n",
    "env = gym.make(env_name)\n",
    "\n",
    "print('Number of states: {}'.format(env.observation_space.shape))\n",
    "print('Number of actions: {}'.format(env.action_space.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, maxlen):\n",
    "        self.buffer = deque(maxlen=maxlen)  #number of experiences to store \n",
    "        \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "        \n",
    "    def sample(self, batch_size):\n",
    "        sample_size = min(len(self.buffer), batch_size)\n",
    "        samples = random.choices(self.buffer, k=sample_size)\n",
    "        return map(list, zip(*samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified Source: https://rubikscode.net/2019/07/08/deep-q-learning-with-python-and-tensorflow-2-0/\n",
    "\n",
    "class DQAgent: \n",
    "    def __init__(self, gamma, epsilon, eps_min, environment, optimizer, input_dims, fc1, fc2):\n",
    "        #initialize state and action space based on environment object\n",
    "        self.state_size = env.observation_space.shape[0]\n",
    "        self.action_size = environment.action_space.n\n",
    "        self.optimizer = optimizer\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_min\n",
    "        \n",
    "        #initilize the replay memory\n",
    "        self.replay_buffer = ReplayBuffer(maxlen=5000)   \n",
    "      \n",
    "        #build the Q Network and Target network\n",
    "        self.q_network = self.build_dqn(self.action_size, input_dims, fc1, fc2)\n",
    "        self.target_network = self.build_dqn(self.action_size, input_dims, fc1, fc2)\n",
    "        \n",
    "        #align the weights\n",
    "        self.align_target_model()  #this is causing a problem because it is getting called too soon\n",
    "        \n",
    "    #append experience to experience memory        \n",
    "    def store(self, state, action, reward, next_state, terminated):\n",
    "        if terminated:\n",
    "            self.epsilon = max(eps_min, 0.99 * self.epsilon)\n",
    "        self.replay_buffer.add((state, action, reward, next_state, (1-int(terminated))))\n",
    "\n",
    "\n",
    "    #Build deep q network \n",
    "    def build_dqn(self, n_actions, input_dims, fc1, fc2): #fc = fully connected dimensions\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(fc1, input_shape = input_dims, activation='relu'), \n",
    "            keras.layers.Dense(fc2, activation='relu'), \n",
    "            keras.layers.Dense(n_actions, activation=None), #output layer, n_actions is number of available actions\n",
    "        ])\n",
    "\n",
    "        model.compile(loss='mse', optimizer = self.optimizer)\n",
    "        return model\n",
    "\n",
    "    def align_target_model(self):\n",
    "        self.target_network.set_weights(\n",
    "            self.q_network.get_weights()) #passes q_network weights to target model\n",
    "\n",
    "    #exploration vs. exploitation with probability of epsilon\n",
    "    def act(self, state):        \n",
    "        state = np.array([state])\n",
    "        q_values = self.q_network.predict(state)\n",
    "        action_greedy = np.argmax(q_values[0])\n",
    "        action_random = np.random.randint(self.action_size)\n",
    "        action = action_random if random.random() < self.epsilon else action_greedy\n",
    "\n",
    "        return action\n",
    "\n",
    "\n",
    "    #take random samples from experience replay memory and train the q_network\n",
    "    def retrain(self, batch_size):\n",
    "\n",
    "        states, actions,rewards, next_states,terms = self.replay_buffer.sample(batch_size)\n",
    "    \n",
    "        states = np.array(states)\n",
    "        next_states = np.array(next_states)\n",
    "        \n",
    "        q_network = self.q_network.predict(states)\n",
    "        q_next = self.q_network.predict(next_states)\n",
    "\n",
    "        q_target = np.copy(q_network)\n",
    "        batch_index = np.arange(len(q_target), dtype=np.int32)\n",
    "\n",
    "        \n",
    "        q_target[batch_index, actions] = rewards + self.gamma * np.ndarray.max(q_next, axis=1) * terms\n",
    "        \n",
    "        self.q_network.train_on_batch(states,q_target)\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'LunarLander-v2'\n",
    "env = gym.make(env_name)\n",
    "env = gym.wrappers.Monitor(env, \"./vid\", video_callable=lambda episode_id: episode_id%10==0)\n",
    "'''\n",
    "Hyperparameters are all here so I can tune them all in the same spot\n",
    "\n",
    "Learning rate\n",
    "gamma\n",
    "epsilon\n",
    "optimizer\n",
    "Dense layer shape\n",
    "'''\n",
    "lr = 0.001\n",
    "gam = 0.99\n",
    "eps = 1.0\n",
    "eps_min = 0.01\n",
    "opt = Adam(learning_rate=lr)\n",
    "dims = env.observation_space.shape\n",
    "layer_1 = 64\n",
    "layer_2 = 64\n",
    "\n",
    "agent = DQAgent(gamma = gam, epsilon = eps, eps_min = eps_min, environment = env, optimizer = opt, \n",
    "                input_dims = dims, fc1 = layer_1, fc2 = layer_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, total reward: -143.6031547666359, epsilon: 0.99\n",
      "Episode: 1, total reward: -261.0653915368299, epsilon: 0.9801\n",
      "Episode: 2, total reward: -248.26381099173358, epsilon: 0.9702989999999999\n",
      "Episode: 3, total reward: -255.13863519697026, epsilon: 0.96059601\n",
      "Episode: 4, total reward: -157.5240027299919, epsilon: 0.9509900498999999\n",
      "Episode: 5, total reward: -120.00223362081795, epsilon: 0.9414801494009999\n",
      "Episode: 6, total reward: -6.931918644972583, epsilon: 0.9320653479069899\n",
      "Episode: 7, total reward: -529.6516733245303, epsilon: 0.92274469442792\n",
      "Episode: 8, total reward: -37.61576061595905, epsilon: 0.9135172474836407\n",
      "Episode: 9, total reward: -167.6971716353994, epsilon: 0.9043820750088043\n",
      "Episode: 10, total reward: -249.40421743898403, epsilon: 0.8953382542587163\n",
      "Episode: 11, total reward: -118.8817262814494, epsilon: 0.8863848717161291\n",
      "Episode: 12, total reward: -75.03912769727961, epsilon: 0.8775210229989678\n",
      "Episode: 13, total reward: -203.53484672917608, epsilon: 0.8687458127689781\n",
      "Episode: 14, total reward: -217.49840477384066, epsilon: 0.8600583546412883\n",
      "Episode: 15, total reward: -65.59010731693806, epsilon: 0.8514577710948754\n",
      "Episode: 16, total reward: -45.1068994212966, epsilon: 0.8429431933839266\n",
      "Episode: 17, total reward: -89.52927185601735, epsilon: 0.8345137614500874\n",
      "Episode: 18, total reward: -142.78162963100766, epsilon: 0.8261686238355865\n",
      "Episode: 19, total reward: -217.19147789124042, epsilon: 0.8179069375972307\n",
      "Episode: 20, total reward: -227.89473201969247, epsilon: 0.8097278682212583\n",
      "Episode: 21, total reward: -81.7753948055875, epsilon: 0.8016305895390458\n",
      "Episode: 22, total reward: -93.27463631822835, epsilon: 0.7936142836436553\n",
      "Episode: 23, total reward: -102.09799727360797, epsilon: 0.7856781408072188\n",
      "Episode: 24, total reward: -223.31880896228057, epsilon: 0.7778213593991465\n",
      "Episode: 25, total reward: -118.02048851700451, epsilon: 0.7700431458051551\n",
      "Episode: 26, total reward: -150.06972496222113, epsilon: 0.7623427143471035\n",
      "Episode: 27, total reward: -47.681718742400406, epsilon: 0.7547192872036325\n",
      "Episode: 28, total reward: -145.02914032110132, epsilon: 0.7471720943315961\n",
      "Episode: 29, total reward: -55.97568071729363, epsilon: 0.7397003733882802\n",
      "Episode: 30, total reward: -258.42689691111764, epsilon: 0.7323033696543974\n",
      "Episode: 31, total reward: -262.56234488218047, epsilon: 0.7249803359578534\n",
      "Episode: 32, total reward: -78.1513025135582, epsilon: 0.7177305325982748\n",
      "Episode: 33, total reward: -193.76677295888345, epsilon: 0.7105532272722921\n",
      "Episode: 34, total reward: -50.66115909560917, epsilon: 0.7034476949995692\n",
      "Episode: 35, total reward: -127.16075637390927, epsilon: 0.6964132180495735\n",
      "Episode: 36, total reward: -111.6071814480237, epsilon: 0.6894490858690777\n",
      "Episode: 37, total reward: -48.34850932966913, epsilon: 0.682554595010387\n",
      "Episode: 38, total reward: -68.63456521093758, epsilon: 0.6757290490602831\n",
      "Episode: 39, total reward: -134.78716409888054, epsilon: 0.6689717585696803\n",
      "Episode: 40, total reward: -93.9959127941321, epsilon: 0.6622820409839835\n",
      "Episode: 41, total reward: -43.85883973843062, epsilon: 0.6556592205741436\n",
      "Episode: 42, total reward: -98.94236677653511, epsilon: 0.6491026283684022\n",
      "Episode: 43, total reward: -45.83674569703744, epsilon: 0.6426116020847181\n",
      "Episode: 44, total reward: -36.85395047488848, epsilon: 0.6361854860638709\n",
      "Episode: 45, total reward: -58.3391101003352, epsilon: 0.6298236312032323\n",
      "Episode: 46, total reward: -105.32492008951195, epsilon: 0.6235253948912\n",
      "Episode: 47, total reward: -70.37487595856172, epsilon: 0.617290140942288\n",
      "Episode: 48, total reward: 0.4076366181117521, epsilon: 0.6111172395328651\n",
      "Episode: 49, total reward: -97.7675957505472, epsilon: 0.6050060671375365\n",
      "Episode: 50, total reward: -96.65616807584877, epsilon: 0.5989560064661611\n",
      "Episode: 51, total reward: -56.854798503651836, epsilon: 0.5929664464014994\n",
      "Episode: 52, total reward: -61.00092767521873, epsilon: 0.5870367819374844\n",
      "Episode: 53, total reward: -36.8876407769186, epsilon: 0.5811664141181095\n",
      "Episode: 54, total reward: -37.190372819065615, epsilon: 0.5753547499769285\n",
      "Episode: 55, total reward: -17.908514625087918, epsilon: 0.5696012024771592\n",
      "Episode: 56, total reward: -22.430786504571927, epsilon: 0.5639051904523876\n",
      "Episode: 57, total reward: -123.89829534648769, epsilon: 0.5582661385478638\n",
      "Episode: 58, total reward: -66.66569657653147, epsilon: 0.5526834771623851\n",
      "Episode: 59, total reward: 23.597402764558126, epsilon: 0.5471566423907612\n",
      "Episode: 60, total reward: -80.1657538853938, epsilon: 0.5416850759668536\n",
      "Episode: 61, total reward: -86.1722729308686, epsilon: 0.536268225207185\n",
      "Episode: 62, total reward: -48.265703337920826, epsilon: 0.5309055429551132\n",
      "Episode: 63, total reward: -72.5827623556331, epsilon: 0.525596487525562\n",
      "Episode: 64, total reward: -4.662742347323103, epsilon: 0.5203405226503064\n",
      "Episode: 65, total reward: -52.80129896983675, epsilon: 0.5151371174238033\n",
      "Episode: 66, total reward: -8.82361543887265, epsilon: 0.5099857462495653\n",
      "Episode: 67, total reward: -142.7298131324676, epsilon: 0.5048858887870696\n",
      "Episode: 68, total reward: -43.62691201085104, epsilon: 0.4998370298991989\n",
      "Episode: 69, total reward: -105.68472295046843, epsilon: 0.49483865960020695\n",
      "Episode: 70, total reward: -14.619695228149027, epsilon: 0.4898902730042049\n",
      "Episode: 71, total reward: 17.432798562696746, epsilon: 0.48499137027416284\n",
      "Episode: 72, total reward: -35.127147275282354, epsilon: 0.4801414565714212\n",
      "Episode: 73, total reward: -4.068005633740512, epsilon: 0.475340042005707\n",
      "Episode: 74, total reward: -92.43287100812026, epsilon: 0.47058664158564995\n",
      "Episode: 75, total reward: -54.763461053943985, epsilon: 0.4658807751697934\n",
      "Episode: 76, total reward: -30.484023693587645, epsilon: 0.4612219674180955\n",
      "Episode: 77, total reward: -31.34615382896972, epsilon: 0.45660974774391455\n",
      "Episode: 78, total reward: -58.70035491999184, epsilon: 0.4520436502664754\n",
      "Episode: 79, total reward: -91.29671561409499, epsilon: 0.44752321376381066\n",
      "Episode: 80, total reward: -47.29433534486333, epsilon: 0.44304798162617254\n",
      "Episode: 81, total reward: -17.752677260657208, epsilon: 0.4386175018099108\n",
      "Episode: 82, total reward: -89.52085356948771, epsilon: 0.4342313267918117\n",
      "Episode: 83, total reward: -251.83516993948666, epsilon: 0.4298890135238936\n",
      "Episode: 84, total reward: 49.00883310920859, epsilon: 0.42559012338865465\n",
      "Episode: 85, total reward: -170.56597482575148, epsilon: 0.4213342221547681\n",
      "Episode: 86, total reward: -47.52703238544714, epsilon: 0.41712087993322045\n",
      "Episode: 87, total reward: 8.118414960099981, epsilon: 0.41294967113388825\n",
      "Episode: 88, total reward: -163.0707675644963, epsilon: 0.40882017442254937\n",
      "Episode: 89, total reward: -257.26370722403203, epsilon: 0.4047319726783239\n",
      "Episode: 90, total reward: -244.3713414103628, epsilon: 0.40068465295154065\n",
      "Episode: 91, total reward: -127.77918597559385, epsilon: 0.39667780642202527\n",
      "Episode: 92, total reward: -159.88580240413478, epsilon: 0.392711028357805\n",
      "Episode: 93, total reward: -183.61176047526774, epsilon: 0.38878391807422696\n",
      "Episode: 94, total reward: -21.399883192479052, epsilon: 0.3848960788934847\n",
      "Episode: 95, total reward: 12.855189890364736, epsilon: 0.38104711810454983\n",
      "Episode: 96, total reward: 28.06217140010751, epsilon: 0.37723664692350434\n",
      "Episode: 97, total reward: -106.1932201651008, epsilon: 0.37346428045426927\n",
      "Episode: 98, total reward: -292.4947659868128, epsilon: 0.36972963764972655\n",
      "Episode: 99, total reward: 126.96163025933309, epsilon: 0.36603234127322926\n",
      "Episode: 100, total reward: -156.3207687614313, epsilon: 0.36237201786049694\n",
      "Episode: 101, total reward: -130.88285047557304, epsilon: 0.358748297681892\n",
      "Episode: 102, total reward: -93.2683618679834, epsilon: 0.35516081470507305\n",
      "Episode: 103, total reward: -130.14911427215299, epsilon: 0.3516092065580223\n",
      "Episode: 104, total reward: -98.5938269032589, epsilon: 0.34809311449244207\n",
      "Episode: 105, total reward: -69.13594907224953, epsilon: 0.34461218334751764\n",
      "Episode: 106, total reward: -126.33140139810115, epsilon: 0.34116606151404244\n",
      "Episode: 107, total reward: 140.82181122652906, epsilon: 0.337754400898902\n",
      "Episode: 108, total reward: -124.13349375499274, epsilon: 0.334376856889913\n",
      "Episode: 109, total reward: -148.20627897773198, epsilon: 0.33103308832101386\n",
      "Episode: 110, total reward: -243.1208085265004, epsilon: 0.3277227574378037\n",
      "Episode: 111, total reward: -7.285732888600665, epsilon: 0.3244455298634257\n",
      "Episode: 112, total reward: 93.33997045626046, epsilon: 0.3212010745647914\n",
      "Episode: 113, total reward: 51.24940250832134, epsilon: 0.3179890638191435\n",
      "Episode: 114, total reward: 26.303625273052347, epsilon: 0.31480917318095203\n",
      "Episode: 115, total reward: -5.863188341178059, epsilon: 0.3116610814491425\n",
      "Episode: 116, total reward: 62.24045555807018, epsilon: 0.30854447063465107\n",
      "Episode: 117, total reward: 1.5712429990602175, epsilon: 0.30545902592830454\n",
      "Episode: 118, total reward: -142.26907315141614, epsilon: 0.3024044356690215\n",
      "Episode: 119, total reward: -145.53405289356556, epsilon: 0.29938039131233124\n",
      "Episode: 120, total reward: -85.15650727668027, epsilon: 0.2963865873992079\n",
      "Episode: 121, total reward: 35.10765006096511, epsilon: 0.29342272152521587\n",
      "Episode: 122, total reward: -138.74479586546272, epsilon: 0.2904884943099637\n",
      "Episode: 123, total reward: -243.47933118816925, epsilon: 0.28758360936686406\n",
      "Episode: 124, total reward: -77.41113706805898, epsilon: 0.2847077732731954\n",
      "Episode: 125, total reward: -138.63935191139788, epsilon: 0.28186069554046345\n",
      "Episode: 126, total reward: -94.76118429085625, epsilon: 0.2790420885850588\n",
      "Episode: 127, total reward: 23.425916400497844, epsilon: 0.2762516676992082\n",
      "Episode: 128, total reward: -108.9844606704751, epsilon: 0.27348915102221616\n",
      "Episode: 129, total reward: 77.00611778969458, epsilon: 0.270754259511994\n",
      "Episode: 130, total reward: -117.74711888226344, epsilon: 0.26804671691687404\n",
      "Episode: 131, total reward: -126.93660363618439, epsilon: 0.2653662497477053\n",
      "Episode: 132, total reward: 21.004105310061313, epsilon: 0.2627125872502282\n",
      "Episode: 133, total reward: 62.37066868039738, epsilon: 0.2600854613777259\n",
      "Episode: 134, total reward: -253.98280271506624, epsilon: 0.2574846067639487\n",
      "Episode: 135, total reward: 63.83449040018713, epsilon: 0.2549097606963092\n",
      "Episode: 136, total reward: -197.8070011299428, epsilon: 0.2523606630893461\n",
      "Episode: 137, total reward: -121.50053431511706, epsilon: 0.24983705645845267\n",
      "Episode: 138, total reward: 45.85866784398965, epsilon: 0.24733868589386815\n",
      "Episode: 139, total reward: 73.42198550049393, epsilon: 0.24486529903492946\n",
      "Episode: 140, total reward: 155.66136252145074, epsilon: 0.24241664604458016\n",
      "Episode: 141, total reward: -32.054027852672476, epsilon: 0.23999247958413436\n",
      "Episode: 142, total reward: 9.67930250185782, epsilon: 0.23759255478829303\n",
      "Episode: 143, total reward: -0.974830755385085, epsilon: 0.2352166292404101\n",
      "Episode: 144, total reward: -50.29141032249829, epsilon: 0.232864462948006\n",
      "Episode: 145, total reward: -16.384711496794477, epsilon: 0.23053581831852593\n",
      "Episode: 146, total reward: -37.07491529248867, epsilon: 0.22823046013534068\n",
      "Episode: 147, total reward: 18.301759618583, epsilon: 0.22594815553398728\n",
      "Episode: 148, total reward: -201.6154331762308, epsilon: 0.22368867397864742\n",
      "Episode: 149, total reward: -180.2923856720114, epsilon: 0.22145178723886094\n",
      "Episode: 150, total reward: -66.89866559981184, epsilon: 0.21923726936647234\n",
      "Episode: 151, total reward: 31.762299272991886, epsilon: 0.2170448966728076\n",
      "Episode: 152, total reward: -76.87361642644451, epsilon: 0.21487444770607952\n",
      "Episode: 153, total reward: 204.75942604990493, epsilon: 0.21272570322901874\n",
      "Episode: 154, total reward: 109.87466401775964, epsilon: 0.21059844619672854\n",
      "Episode: 155, total reward: -69.53161900073394, epsilon: 0.20849246173476127\n",
      "Episode: 156, total reward: 124.18004461157132, epsilon: 0.20640753711741366\n",
      "Episode: 157, total reward: -133.8916524709586, epsilon: 0.20434346174623952\n",
      "Episode: 158, total reward: -129.48646339032223, epsilon: 0.20230002712877712\n",
      "Episode: 159, total reward: 108.10016190141262, epsilon: 0.20027702685748935\n",
      "Episode: 160, total reward: -10.537941016586217, epsilon: 0.19827425658891445\n",
      "Episode: 161, total reward: -35.39477040110852, epsilon: 0.1962915140230253\n",
      "Episode: 162, total reward: 229.11184376476658, epsilon: 0.19432859888279505\n",
      "Episode: 163, total reward: 173.12358531433443, epsilon: 0.1923853128939671\n",
      "Episode: 164, total reward: 59.59403654040247, epsilon: 0.19046145976502743\n",
      "Episode: 165, total reward: 148.00887766960335, epsilon: 0.18855684516737714\n",
      "Episode: 166, total reward: -417.76999759429737, epsilon: 0.18667127671570335\n",
      "Episode: 167, total reward: -39.622713530217794, epsilon: 0.18480456394854633\n",
      "Episode: 168, total reward: -205.64227164931276, epsilon: 0.18295651830906087\n",
      "Episode: 169, total reward: -209.60275549984178, epsilon: 0.18112695312597027\n",
      "Episode: 170, total reward: 98.00679945643235, epsilon: 0.17931568359471056\n",
      "Episode: 171, total reward: 25.65024581849623, epsilon: 0.17752252675876345\n",
      "Episode: 172, total reward: 270.36317684708354, epsilon: 0.17574730149117582\n",
      "Episode: 173, total reward: -212.58755922879513, epsilon: 0.17398982847626407\n",
      "Episode: 174, total reward: -181.16810611886223, epsilon: 0.17224993019150142\n",
      "Episode: 175, total reward: 108.20681753896179, epsilon: 0.1705274308895864\n",
      "Episode: 176, total reward: 127.99367436880252, epsilon: 0.16882215658069055\n",
      "Episode: 177, total reward: 130.87119463296554, epsilon: 0.16713393501488363\n",
      "Episode: 178, total reward: 13.497127361122393, epsilon: 0.16546259566473479\n",
      "Episode: 179, total reward: 21.88767148786829, epsilon: 0.16380796970808745\n",
      "Episode: 180, total reward: 29.91917451229477, epsilon: 0.16216989001100657\n",
      "Episode: 181, total reward: 216.09383108441637, epsilon: 0.1605481911108965\n",
      "Episode: 182, total reward: -182.057458138319, epsilon: 0.15894270919978754\n",
      "Episode: 183, total reward: -248.37761186949587, epsilon: 0.15735328210778965\n",
      "Episode: 184, total reward: 105.81535338615085, epsilon: 0.15577974928671176\n",
      "Episode: 185, total reward: 126.73556278411318, epsilon: 0.15422195179384465\n",
      "Episode: 186, total reward: 136.27478766039667, epsilon: 0.1526797322759062\n",
      "Episode: 187, total reward: 146.90965560525913, epsilon: 0.15115293495314713\n",
      "Episode: 188, total reward: 162.82354359371166, epsilon: 0.14964140560361566\n",
      "Episode: 189, total reward: 17.799782575907344, epsilon: 0.1481449915475795\n",
      "Episode: 190, total reward: 207.3902415197948, epsilon: 0.1466635416321037\n",
      "Episode: 191, total reward: 101.96863296195346, epsilon: 0.14519690621578268\n",
      "Episode: 192, total reward: -429.76631962550823, epsilon: 0.14374493715362485\n",
      "Episode: 193, total reward: 69.37486913611974, epsilon: 0.1423074877820886\n",
      "Episode: 194, total reward: 190.33304980757322, epsilon: 0.1408844129042677\n",
      "Episode: 195, total reward: 269.9945386382651, epsilon: 0.13947556877522502\n",
      "Episode: 196, total reward: 251.73431279586828, epsilon: 0.13808081308747278\n",
      "Episode: 197, total reward: 219.8477735034176, epsilon: 0.13670000495659804\n",
      "Episode: 198, total reward: 236.4773392804566, epsilon: 0.13533300490703207\n",
      "Episode: 199, total reward: 210.00710430865405, epsilon: 0.13397967485796175\n",
      "Episode: 200, total reward: -184.55397080427417, epsilon: 0.13263987810938213\n",
      "Episode: 201, total reward: 224.01073290394845, epsilon: 0.1313134793282883\n",
      "Episode: 202, total reward: 220.98987847777408, epsilon: 0.13000034453500542\n",
      "Episode: 203, total reward: 241.88602734449648, epsilon: 0.12870034108965536\n",
      "Episode: 204, total reward: 72.76030911098728, epsilon: 0.12741333767875881\n",
      "Episode: 205, total reward: -130.79283499305907, epsilon: 0.12613920430197123\n",
      "Episode: 206, total reward: -120.03674747060357, epsilon: 0.12487781225895152\n",
      "Episode: 207, total reward: -195.1513112590016, epsilon: 0.123629034136362\n",
      "Episode: 208, total reward: 210.3404627157047, epsilon: 0.12239274379499838\n",
      "Episode: 209, total reward: 154.9889163119151, epsilon: 0.1211688163570484\n",
      "Episode: 210, total reward: -75.71935917359629, epsilon: 0.11995712819347792\n",
      "Episode: 211, total reward: 233.65567601323946, epsilon: 0.11875755691154315\n",
      "Episode: 212, total reward: 214.62403384907284, epsilon: 0.11756998134242772\n",
      "Episode: 213, total reward: -200.6886212014882, epsilon: 0.11639428152900344\n",
      "Episode: 214, total reward: -66.47675012611487, epsilon: 0.11523033871371341\n",
      "Episode: 215, total reward: 208.75138721955287, epsilon: 0.11407803532657627\n",
      "Episode: 216, total reward: 33.158690013225275, epsilon: 0.11293725497331052\n",
      "Episode: 217, total reward: 216.2303785092472, epsilon: 0.1118078824235774\n",
      "Episode: 218, total reward: 198.3185554974422, epsilon: 0.11068980359934164\n",
      "Episode: 219, total reward: 25.625785669144317, epsilon: 0.10958290556334822\n",
      "Episode: 220, total reward: 45.9611009729725, epsilon: 0.10848707650771475\n",
      "Episode: 221, total reward: -404.2841296883388, epsilon: 0.1074022057426376\n",
      "Episode: 222, total reward: -355.8240020757271, epsilon: 0.10632818368521123\n",
      "Episode: 223, total reward: 14.632728830986398, epsilon: 0.10526490184835911\n",
      "Episode: 224, total reward: -6.224385964123399, epsilon: 0.10421225282987552\n",
      "Episode: 225, total reward: 15.49159882845031, epsilon: 0.10317013030157676\n",
      "Episode: 226, total reward: -139.9348275585058, epsilon: 0.10213842899856099\n",
      "Episode: 227, total reward: -106.20639149084974, epsilon: 0.10111704470857538\n",
      "Episode: 228, total reward: 191.73893634944747, epsilon: 0.10010587426148963\n",
      "Episode: 229, total reward: 136.33393485878008, epsilon: 0.09910481551887473\n",
      "Episode: 230, total reward: 155.29215439675048, epsilon: 0.09811376736368599\n",
      "Episode: 231, total reward: 187.44444416677322, epsilon: 0.09713262969004913\n",
      "Episode: 232, total reward: 186.21855314486595, epsilon: 0.09616130339314863\n",
      "Episode: 233, total reward: 155.59488220787125, epsilon: 0.09519969035921715\n",
      "Episode: 234, total reward: 180.83149777028368, epsilon: 0.09424769345562498\n",
      "Episode: 235, total reward: 174.2188924225053, epsilon: 0.09330521652106873\n",
      "Episode: 236, total reward: 214.7702087332026, epsilon: 0.09237216435585804\n",
      "Episode: 237, total reward: -29.07453325453851, epsilon: 0.09144844271229946\n",
      "Episode: 238, total reward: 114.16359467440437, epsilon: 0.09053395828517646\n",
      "Episode: 239, total reward: 128.70943027704521, epsilon: 0.08962861870232469\n",
      "Episode: 240, total reward: -30.80057004089882, epsilon: 0.08873233251530144\n",
      "Episode: 241, total reward: 236.09261490690722, epsilon: 0.08784500919014843\n",
      "Episode: 242, total reward: -72.64180632465036, epsilon: 0.08696655909824694\n",
      "Episode: 243, total reward: -62.512426425034995, epsilon: 0.08609689350726446\n",
      "Episode: 244, total reward: 182.55636488062942, epsilon: 0.08523592457219181\n",
      "Episode: 245, total reward: 190.7118742788097, epsilon: 0.0843835653264699\n",
      "Episode: 246, total reward: 10.352266215826777, epsilon: 0.0835397296732052\n",
      "Episode: 247, total reward: 57.96544580171238, epsilon: 0.08270433237647315\n",
      "Episode: 248, total reward: 11.727395834728764, epsilon: 0.08187728905270841\n",
      "Episode: 249, total reward: 203.45921773420105, epsilon: 0.08105851616218133\n",
      "Episode: 250, total reward: 206.57883208016318, epsilon: 0.08024793100055952\n",
      "Episode: 251, total reward: 242.7553459670366, epsilon: 0.07944545169055392\n",
      "Episode: 252, total reward: -12.191748610896866, epsilon: 0.07865099717364837\n",
      "Episode: 253, total reward: -153.0886435338378, epsilon: 0.07786448720191189\n",
      "Episode: 254, total reward: -65.6977155590117, epsilon: 0.07708584232989277\n",
      "Episode: 255, total reward: -233.4204357572827, epsilon: 0.07631498390659384\n",
      "Episode: 256, total reward: -98.69460588560601, epsilon: 0.07555183406752791\n",
      "Episode: 257, total reward: -378.6918274532511, epsilon: 0.07479631572685264\n",
      "Episode: 258, total reward: -282.7935363725402, epsilon: 0.07404835256958411\n",
      "Episode: 259, total reward: 171.15473656014365, epsilon: 0.07330786904388827\n",
      "Episode: 260, total reward: 253.3944479204049, epsilon: 0.07257479035344938\n",
      "Episode: 261, total reward: 198.35176712024634, epsilon: 0.07184904244991488\n",
      "Episode: 262, total reward: 82.84593231210741, epsilon: 0.07113055202541574\n",
      "Episode: 263, total reward: 208.77367655953765, epsilon: 0.07041924650516158\n",
      "Episode: 264, total reward: 205.04225183890512, epsilon: 0.06971505404010997\n",
      "Episode: 265, total reward: 121.73318713792237, epsilon: 0.06901790349970886\n",
      "Episode: 266, total reward: 23.323353771822934, epsilon: 0.06832772446471178\n",
      "Episode: 267, total reward: 213.52646206984505, epsilon: 0.06764444722006466\n",
      "Episode: 268, total reward: 45.46978855188727, epsilon: 0.066968002747864\n",
      "Episode: 269, total reward: -95.33488925420484, epsilon: 0.06629832272038537\n",
      "Episode: 270, total reward: 127.42482996987421, epsilon: 0.06563533949318151\n",
      "Episode: 271, total reward: 99.46761483947483, epsilon: 0.06497898609824969\n",
      "Episode: 272, total reward: -125.87977868656428, epsilon: 0.0643291962372672\n",
      "Episode: 273, total reward: 30.845456864131524, epsilon: 0.06368590427489453\n",
      "Episode: 274, total reward: -229.36621399901372, epsilon: 0.06304904523214558\n",
      "Episode: 275, total reward: 251.93151333223167, epsilon: 0.06241855477982412\n",
      "Episode: 276, total reward: -8.839949444908655, epsilon: 0.06179436923202588\n",
      "Episode: 277, total reward: -193.11739442548642, epsilon: 0.06117642553970562\n",
      "Episode: 278, total reward: -358.4760397493123, epsilon: 0.06056466128430856\n",
      "Episode: 279, total reward: -391.6029720962785, epsilon: 0.05995901467146548\n",
      "Episode: 280, total reward: 155.33492369256123, epsilon: 0.05935942452475082\n",
      "Episode: 281, total reward: -281.2127557809008, epsilon: 0.058765830279503314\n",
      "Episode: 282, total reward: -245.27808605719437, epsilon: 0.05817817197670828\n",
      "Episode: 283, total reward: -201.70249477383135, epsilon: 0.057596390256941195\n",
      "Episode: 284, total reward: -199.73235142413802, epsilon: 0.05702042635437178\n",
      "Episode: 285, total reward: -345.5755115293244, epsilon: 0.05645022209082806\n",
      "Episode: 286, total reward: -216.4049706011652, epsilon: 0.05588571986991978\n",
      "Episode: 287, total reward: 132.64758649604823, epsilon: 0.055326862671220584\n",
      "Episode: 288, total reward: -94.68966500675384, epsilon: 0.05477359404450838\n",
      "Episode: 289, total reward: 10.477124654586024, epsilon: 0.054225858104063294\n",
      "Episode: 290, total reward: -258.3064752629763, epsilon: 0.05368359952302266\n",
      "Episode: 291, total reward: -262.7459517598247, epsilon: 0.053146763527792434\n",
      "Episode: 292, total reward: -322.5248912328759, epsilon: 0.052615295892514506\n",
      "Episode: 293, total reward: -379.02321715754124, epsilon: 0.052089142933589364\n",
      "Episode: 294, total reward: -174.97408722360026, epsilon: 0.05156825150425347\n",
      "Episode: 295, total reward: 196.29475976791323, epsilon: 0.051052568989210935\n",
      "Episode: 296, total reward: -45.74355222729578, epsilon: 0.05054204329931883\n",
      "Episode: 297, total reward: -125.67547121644144, epsilon: 0.05003662286632564\n",
      "Episode: 298, total reward: -150.11029182409428, epsilon: 0.04953625663766238\n",
      "Episode: 299, total reward: -232.06369938786654, epsilon: 0.04904089407128576\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "num_episodes = 300\n",
    "\n",
    "total_rewards = []\n",
    "for e in range(num_episodes): \n",
    "    #reset the environment to get random initial state\n",
    "    state = env.reset()\n",
    "   \n",
    "    total_reward = 0\n",
    "    terminated = False\n",
    "    \n",
    "    while not terminated:\n",
    "        env.render()\n",
    "        action = agent.act(state)      \n",
    "\n",
    "        # take action \n",
    "        next_state, reward, terminated, info = env.step(action)\n",
    "\n",
    "        # train = store experience in buffer, get samples\n",
    "        total_reward += reward\n",
    "        \n",
    "        agent.store(state, action, reward, next_state, terminated) #add experience to buffer         \n",
    "        state = next_state\n",
    "        agent.retrain(batch_size)\n",
    "    total_rewards.append(total_reward)\n",
    "        \n",
    "    print(\"Episode: {}, total reward: {}, epsilon: {}\".format(e,total_reward, agent.epsilon))\n",
    "\n",
    "    \n",
    "    \n",
    "x = [i for i in range(num_episodes)]\n",
    "\n",
    "env.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = len(total_rewards)\n",
    "running_avg = np.empty(N)\n",
    "for t in range(N):\n",
    "    running_avg[t] = np.mean(total_rewards[max(0, t-20):(t+1)])\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Score')\n",
    "plt.scatter(x, running_avg, color=\"steelblue\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
