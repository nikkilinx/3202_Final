{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Final_DQN_complete_run-3-with_Notes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4IwrNBwW_T5"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "\n",
        "# from IPython.display import clear_output\n",
        "from collections import deque\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Reshape\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGTahnPtXFf_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVw7A8tpW_T5",
        "outputId": "f9eabebe-292b-4b4a-8e8f-ca721b2f636d"
      },
      "source": [
        "\n",
        "env_name = 'LunarLander-v2'\n",
        "# env_name = 'CarRacing-v0'\n",
        "env = gym.make(env_name)\n",
        "\n",
        "print('Number of states: {}'.format(env.observation_space.shape))\n",
        "print('Number of actions: {}'.format(env.action_space.n))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of states: (8,)\n",
            "Number of actions: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UryXcl4MXGd7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DyInoeoW_T6"
      },
      "source": [
        "class ReplayBuffer:\n",
        "    def __init__(self, maxlen):\n",
        "        self.buffer = deque(maxlen=maxlen)  #number of experiences to store \n",
        "        \n",
        "    def add(self, experience):\n",
        "        self.buffer.append(experience)\n",
        "        \n",
        "    def sample(self, batch_size):\n",
        "        sample_size = min(len(self.buffer), batch_size)\n",
        "        samples = random.choices(self.buffer, k=sample_size)\n",
        "        return map(list, zip(*samples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57MlM0k_W_T6"
      },
      "source": [
        "#Modified Source: https://rubikscode.net/2019/07/08/deep-q-learning-with-python-and-tensorflow-2-0/\n",
        "'''\n",
        "DQAgent \n",
        "Builds an AI agent using a DQN. Initialized with a gamma value, epsilon value, a minimum value for epsilon, \n",
        "an environment, an optimizer, input dimensions, and the sizes for the 2 fully connected layers of the model. \n",
        "\n",
        "Methods: \n",
        "store: If an episode is terminated, the epsilon value is reduced by the decay rate. \n",
        "This pushes the agent from exploration to exploitation as the agent learns. \n",
        "Also stores the episodes in the replay buffer using the add method of the ReplayBuffer class. \n",
        "\n",
        "build_dqn: Builds a Sequental model with 3 Dense layers. The input layersize is \n",
        "the shape of the observation space of the environment. The output layer is the number \n",
        "of available actions. The fc1 and fc2 input are the dimensions of the input and hidden layer. \n",
        "\n",
        "align_target_model: Initializes the target network with the same weights as the \n",
        "initial q_network. \n",
        "\n",
        "act: Gets the action the agent will take based on the state, the max value of \n",
        "the available actions, and the epsilon greedy method. The action returns a random action \n",
        "with the probability of epsilon. \n",
        "\n",
        "retrain: Updates the q_network using random samples from the stored episodes in \n",
        "the ReplayBuffer, and based on the Bellman equation, using the target \n",
        "network to stabilize the learning. \n",
        "\n",
        "'''\n",
        "class DQAgent: \n",
        "    def __init__(self, gamma, epsilon, eps_min, environment, optimizer, input_dims, fc1, fc2):\n",
        "        #initialize state and action space based on environment object\n",
        "        self.state_size = env.observation_space.shape[0]\n",
        "        self.action_size = environment.action_space.n\n",
        "        self.optimizer = optimizer\n",
        "        self.gamma = gamma\n",
        "        self.epsilon = epsilon\n",
        "        self.eps_min = eps_min\n",
        "        \n",
        "        #initilize the replay memory\n",
        "        self.replay_buffer = ReplayBuffer(maxlen=10000)   \n",
        "      \n",
        "        #build the Q Network and Target network\n",
        "        self.q_network = self.build_dqn(self.action_size, input_dims, fc1, fc2)\n",
        "        self.target_network = self.build_dqn(self.action_size, input_dims, fc1, fc2)\n",
        "        \n",
        "        #align the weights\n",
        "        self.align_target_model() \n",
        "        \n",
        "    #append experience to experience memory        \n",
        "    def store(self, state, action, reward, next_state, terminated):\n",
        "        if terminated:\n",
        "            self.epsilon = max(eps_min, 0.99 * self\n",
        "                               .epsilon)\n",
        "        self.replay_buffer.add((state, action, reward, next_state, (1-int(terminated))))\n",
        "\n",
        "\n",
        "    #Build deep q network \n",
        "    def build_dqn(self, n_actions, input_dims, fc1, fc2): #fc = fully connected dimensions\n",
        "        model = keras.Sequential([\n",
        "            keras.layers.Dense(fc1, input_shape = input_dims, activation='relu'),             \n",
        "            keras.layers.Dense(fc2, activation='relu'), \n",
        "            keras.layers.Dense(n_actions, activation=None), #output layer, n_actions is number of available actions\n",
        "        ])\n",
        "\n",
        "        model.compile(loss='mse', optimizer = self.optimizer)\n",
        "        return model\n",
        "\n",
        "    def align_target_model(self):\n",
        "        self.target_network.set_weights(\n",
        "            self.q_network.get_weights()) #passes q_network weights to target model\n",
        "\n",
        "    #exploration vs. exploitation with probability of epsilon\n",
        "    def act(self, state):        \n",
        "        state = np.array([state])\n",
        "        q_values = self.q_network.predict(state)\n",
        "        action_greedy = np.argmax(q_values[0])\n",
        "        action_random = np.random.randint(self.action_size)\n",
        "        action = action_random if random.random() < self.epsilon else action_greedy\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "    #take random samples from experience replay memory and train the q_network\n",
        "    def retrain(self, batch_size):\n",
        "\n",
        "        states, actions,rewards, next_states,terms = self.replay_buffer.sample(batch_size)\n",
        "    \n",
        "        states = np.array(states)\n",
        "        next_states = np.array(next_states)\n",
        "        \n",
        "        q_network = self.q_network.predict(states)\n",
        "        q_next = self.q_network.predict(next_states)\n",
        "\n",
        "        q_target = np.copy(q_network)\n",
        "        batch_index = np.arange(len(q_target), dtype=np.int32)\n",
        "\n",
        "        \n",
        "        q_target[batch_index, actions] = rewards + self.gamma * np.ndarray.max(q_next, axis=1) * terms\n",
        "        \n",
        "        self.q_network.train_on_batch(states,q_target)\n",
        "                \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTet-U7cW_T6"
      },
      "source": [
        "env_name = 'LunarLander-v2'\n",
        "env = gym.make(env_name)\n",
        "env = gym.wrappers.Monitor(env, \"./vid3\", video_callable=lambda episode_id: episode_id%10==0)\n",
        "'''\n",
        "Hyperparameters are all here so I can tune them all in the same spot\n",
        "\n",
        "Learning rate\n",
        "gamma\n",
        "epsilon\n",
        "optimizer\n",
        "Dense layer shape\n",
        "'''\n",
        "lr = 0.0005\n",
        "gam = 0.99\n",
        "eps = 1.0\n",
        "eps_min = 0.01\n",
        "opt = Adam(learning_rate=lr)\n",
        "dims = env.observation_space.shape\n",
        "layer_1 = 64\n",
        "layer_2 = 64\n",
        "\n",
        "agent = DQAgent(gamma = gam, epsilon = eps, eps_min = eps_min, environment = env, optimizer = opt, \n",
        "                input_dims = dims, fc1 = layer_1, fc2 = layer_2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "UeAnZQU1W_T6",
        "outputId": "95e97dd9-021b-4baa-bf9d-b423fa8d4144"
      },
      "source": [
        "batch_size = 64\n",
        "num_episodes = 500\n",
        "total_rewards = []\n",
        "start_time = time.time()\n",
        "for e in range(num_episodes): \n",
        "    #reset the environment to get random initial state\n",
        "    state = env.reset()\n",
        "   \n",
        "    total_reward = 0\n",
        "    terminated = False\n",
        "    \n",
        "    while not terminated:\n",
        "        env.render()\n",
        "        action = agent.act(state)      \n",
        "\n",
        "        # take action \n",
        "        next_state, reward, terminated, info = env.step(action)\n",
        "\n",
        "        # train = store experience in buffer, get samples\n",
        "        total_reward += reward\n",
        "        \n",
        "        agent.store(state, action, reward, next_state, terminated) #add experience to buffer         \n",
        "        state = next_state\n",
        "        agent.retrain(batch_size)\n",
        "    total_rewards.append(total_reward)       \n",
        "    print(\"Episode: {}, total reward: {}, epsilon: {}\".format(e,total_reward, agent.epsilon))\n",
        "\n",
        "print(\"Total time: %s hours\" % ((time.time() - start_time)/3600))  \n",
        "    \n",
        "    \n",
        "x = [i for i in range(num_episodes)]\n",
        "\n",
        "env.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode: 0, total reward: -226.36609264855755, epsilon: 0.99\n",
            "Episode: 1, total reward: -81.98728626732843, epsilon: 0.9801\n",
            "Episode: 2, total reward: -117.4186861323085, epsilon: 0.9702989999999999\n",
            "Episode: 3, total reward: -133.33822860907006, epsilon: 0.96059601\n",
            "Episode: 4, total reward: -327.9103678243599, epsilon: 0.9509900498999999\n",
            "Episode: 5, total reward: -222.56930181799123, epsilon: 0.9414801494009999\n",
            "Episode: 6, total reward: -343.95747213187025, epsilon: 0.9320653479069899\n",
            "Episode: 7, total reward: -286.9153056897922, epsilon: 0.92274469442792\n",
            "Episode: 8, total reward: -49.20342806855217, epsilon: 0.9135172474836407\n",
            "Episode: 9, total reward: -248.01033789253708, epsilon: 0.9043820750088043\n",
            "Episode: 10, total reward: -569.171130442405, epsilon: 0.8953382542587163\n",
            "Episode: 11, total reward: -254.03479465729066, epsilon: 0.8863848717161291\n",
            "Episode: 12, total reward: -93.23258253563475, epsilon: 0.8775210229989678\n",
            "Episode: 13, total reward: -68.28920633598548, epsilon: 0.8687458127689781\n",
            "Episode: 14, total reward: -151.74482415291595, epsilon: 0.8600583546412883\n",
            "Episode: 15, total reward: -254.786703657628, epsilon: 0.8514577710948754\n",
            "Episode: 16, total reward: -102.20061396538556, epsilon: 0.8429431933839266\n",
            "Episode: 17, total reward: -174.51998236643368, epsilon: 0.8345137614500874\n",
            "Episode: 18, total reward: -99.73442698347371, epsilon: 0.8261686238355865\n",
            "Episode: 19, total reward: -130.15962513962756, epsilon: 0.8179069375972307\n",
            "Episode: 20, total reward: -249.9733263448847, epsilon: 0.8097278682212583\n",
            "Episode: 21, total reward: -95.62231176081617, epsilon: 0.8016305895390458\n",
            "Episode: 22, total reward: -100.75747783398128, epsilon: 0.7936142836436553\n",
            "Episode: 23, total reward: -60.923232845670995, epsilon: 0.7856781408072188\n",
            "Episode: 24, total reward: -88.45148056183888, epsilon: 0.7778213593991465\n",
            "Episode: 25, total reward: -467.81226811707444, epsilon: 0.7700431458051551\n",
            "Episode: 26, total reward: -118.34492753330767, epsilon: 0.7623427143471035\n",
            "Episode: 27, total reward: -51.38744027151198, epsilon: 0.7547192872036325\n",
            "Episode: 28, total reward: -33.19319687786752, epsilon: 0.7471720943315961\n",
            "Episode: 29, total reward: -127.31453906176938, epsilon: 0.7397003733882802\n",
            "Episode: 30, total reward: -125.75745475003427, epsilon: 0.7323033696543974\n",
            "Episode: 31, total reward: -86.51701091779725, epsilon: 0.7249803359578534\n",
            "Episode: 32, total reward: -101.13557742279114, epsilon: 0.7177305325982748\n",
            "Episode: 33, total reward: -3.9027197564845295, epsilon: 0.7105532272722921\n",
            "Episode: 34, total reward: -98.13734253375846, epsilon: 0.7034476949995692\n",
            "Episode: 35, total reward: -54.641305162261816, epsilon: 0.6964132180495735\n",
            "Episode: 36, total reward: -93.25611017122029, epsilon: 0.6894490858690777\n",
            "Episode: 37, total reward: -107.71910931681475, epsilon: 0.682554595010387\n",
            "Episode: 38, total reward: -98.34610838544181, epsilon: 0.6757290490602831\n",
            "Episode: 39, total reward: -87.38284752998506, epsilon: 0.6689717585696803\n",
            "Episode: 40, total reward: -107.0273733178029, epsilon: 0.6622820409839835\n",
            "Episode: 41, total reward: -53.70480246709469, epsilon: 0.6556592205741436\n",
            "Episode: 42, total reward: -67.79430918936475, epsilon: 0.6491026283684022\n",
            "Episode: 43, total reward: -66.745031882329, epsilon: 0.6426116020847181\n",
            "Episode: 44, total reward: -30.85460877922975, epsilon: 0.6361854860638709\n",
            "Episode: 45, total reward: -108.75615380498557, epsilon: 0.6298236312032323\n",
            "Episode: 46, total reward: -305.3790542004173, epsilon: 0.6235253948912\n",
            "Episode: 47, total reward: -41.42904970893622, epsilon: 0.617290140942288\n",
            "Episode: 48, total reward: -51.68571603462939, epsilon: 0.6111172395328651\n",
            "Episode: 49, total reward: -39.25019403213855, epsilon: 0.6050060671375365\n",
            "Episode: 50, total reward: -98.50799151737932, epsilon: 0.5989560064661611\n",
            "Episode: 51, total reward: -122.10198999030374, epsilon: 0.5929664464014994\n",
            "Episode: 52, total reward: -58.22024747912319, epsilon: 0.5870367819374844\n",
            "Episode: 53, total reward: -53.74566101339851, epsilon: 0.5811664141181095\n",
            "Episode: 54, total reward: -59.89454330354343, epsilon: 0.5753547499769285\n",
            "Episode: 55, total reward: -186.5105844282495, epsilon: 0.5696012024771592\n",
            "Episode: 56, total reward: 22.56645243583232, epsilon: 0.5639051904523876\n",
            "Episode: 57, total reward: -105.19275839939799, epsilon: 0.5582661385478638\n",
            "Episode: 58, total reward: -126.76780436970772, epsilon: 0.5526834771623851\n",
            "Episode: 59, total reward: 8.477480608684502, epsilon: 0.5471566423907612\n",
            "Episode: 60, total reward: -98.74069426669186, epsilon: 0.5416850759668536\n",
            "Episode: 61, total reward: -82.35498225546647, epsilon: 0.536268225207185\n",
            "Episode: 62, total reward: -54.520324551305606, epsilon: 0.5309055429551132\n",
            "Episode: 63, total reward: -29.519048867639718, epsilon: 0.525596487525562\n",
            "Episode: 64, total reward: -217.44961582340295, epsilon: 0.5203405226503064\n",
            "Episode: 65, total reward: -93.62929974786094, epsilon: 0.5151371174238033\n",
            "Episode: 66, total reward: -6.364658297952275, epsilon: 0.5099857462495653\n",
            "Episode: 67, total reward: -225.7722062284475, epsilon: 0.5048858887870696\n",
            "Episode: 68, total reward: 23.7032610361629, epsilon: 0.4998370298991989\n",
            "Episode: 69, total reward: -39.57697690690155, epsilon: 0.49483865960020695\n",
            "Episode: 70, total reward: -68.23535896925057, epsilon: 0.4898902730042049\n",
            "Episode: 71, total reward: -41.31236311646832, epsilon: 0.48499137027416284\n",
            "Episode: 72, total reward: -18.447547810533816, epsilon: 0.4801414565714212\n",
            "Episode: 73, total reward: 14.062331707500292, epsilon: 0.475340042005707\n",
            "Episode: 74, total reward: -148.09890025742345, epsilon: 0.47058664158564995\n",
            "Episode: 75, total reward: -232.61866079064276, epsilon: 0.4658807751697934\n",
            "Episode: 76, total reward: -49.06698392653061, epsilon: 0.4612219674180955\n",
            "Episode: 77, total reward: -10.07213674469152, epsilon: 0.45660974774391455\n",
            "Episode: 78, total reward: 24.37785851619393, epsilon: 0.4520436502664754\n",
            "Episode: 79, total reward: 8.863484105443282, epsilon: 0.44752321376381066\n",
            "Episode: 80, total reward: -92.88343569820753, epsilon: 0.44304798162617254\n",
            "Episode: 81, total reward: -21.14266528223339, epsilon: 0.4386175018099108\n",
            "Episode: 82, total reward: 64.71191539473033, epsilon: 0.4342313267918117\n",
            "Episode: 83, total reward: 42.29087430097266, epsilon: 0.4298890135238936\n",
            "Episode: 84, total reward: -39.65801388630673, epsilon: 0.42559012338865465\n",
            "Episode: 85, total reward: -20.525625027452804, epsilon: 0.4213342221547681\n",
            "Episode: 86, total reward: -359.43456633742835, epsilon: 0.41712087993322045\n",
            "Episode: 87, total reward: 26.56501549519706, epsilon: 0.41294967113388825\n",
            "Episode: 88, total reward: 90.880679839263, epsilon: 0.40882017442254937\n",
            "Episode: 89, total reward: 3.1117030508230243, epsilon: 0.4047319726783239\n",
            "Episode: 90, total reward: 7.093050647507596, epsilon: 0.40068465295154065\n",
            "Episode: 91, total reward: -199.72524705492708, epsilon: 0.39667780642202527\n",
            "Episode: 92, total reward: 63.255134371410186, epsilon: 0.392711028357805\n",
            "Episode: 93, total reward: 72.95406170395285, epsilon: 0.38878391807422696\n",
            "Episode: 94, total reward: -46.65994457332525, epsilon: 0.3848960788934847\n",
            "Episode: 95, total reward: 63.458586732050335, epsilon: 0.38104711810454983\n",
            "Episode: 96, total reward: -2.5524831344104992, epsilon: 0.37723664692350434\n",
            "Episode: 97, total reward: -78.86056938624215, epsilon: 0.37346428045426927\n",
            "Episode: 98, total reward: 32.64158822782588, epsilon: 0.36972963764972655\n",
            "Episode: 99, total reward: 15.512712562529488, epsilon: 0.36603234127322926\n",
            "Episode: 100, total reward: 2.661340371026796, epsilon: 0.36237201786049694\n",
            "Episode: 101, total reward: 24.254222480193004, epsilon: 0.358748297681892\n",
            "Episode: 102, total reward: 96.75317495365573, epsilon: 0.35516081470507305\n",
            "Episode: 103, total reward: -10.095299312783524, epsilon: 0.3516092065580223\n",
            "Episode: 104, total reward: 68.58971824176034, epsilon: 0.34809311449244207\n",
            "Episode: 105, total reward: 49.48219614651224, epsilon: 0.34461218334751764\n",
            "Episode: 106, total reward: -11.668402188659101, epsilon: 0.34116606151404244\n",
            "Episode: 107, total reward: 78.6287405121912, epsilon: 0.337754400898902\n",
            "Episode: 108, total reward: 90.87376902201808, epsilon: 0.334376856889913\n",
            "Episode: 109, total reward: 145.19677264631954, epsilon: 0.33103308832101386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode: 110, total reward: -87.4041391660984, epsilon: 0.3277227574378037\n",
            "Episode: 111, total reward: -71.28160014527535, epsilon: 0.3244455298634257\n",
            "Episode: 112, total reward: -268.3117262713881, epsilon: 0.3212010745647914\n",
            "Episode: 113, total reward: -362.2802803949803, epsilon: 0.3179890638191435\n",
            "Episode: 114, total reward: -98.07712995736352, epsilon: 0.31480917318095203\n",
            "Episode: 115, total reward: -45.70460038191196, epsilon: 0.3116610814491425\n",
            "Episode: 116, total reward: -123.9494324681768, epsilon: 0.30854447063465107\n",
            "Episode: 117, total reward: -44.00181044447298, epsilon: 0.30545902592830454\n",
            "Episode: 118, total reward: -85.92313886391764, epsilon: 0.3024044356690215\n",
            "Episode: 119, total reward: -198.81197243957348, epsilon: 0.29938039131233124\n",
            "Episode: 120, total reward: 46.50128827240191, epsilon: 0.2963865873992079\n",
            "Episode: 121, total reward: 105.0175640030955, epsilon: 0.29342272152521587\n",
            "Episode: 122, total reward: 20.489661228247698, epsilon: 0.2904884943099637\n",
            "Episode: 123, total reward: 86.37162949852545, epsilon: 0.28758360936686406\n",
            "Episode: 124, total reward: 98.77612403383425, epsilon: 0.2847077732731954\n",
            "Episode: 125, total reward: -110.86196660423421, epsilon: 0.28186069554046345\n",
            "Episode: 126, total reward: 62.497076186478616, epsilon: 0.2790420885850588\n",
            "Episode: 127, total reward: 13.41671005613847, epsilon: 0.2762516676992082\n",
            "Episode: 128, total reward: -76.10427903752696, epsilon: 0.27348915102221616\n",
            "Episode: 129, total reward: -69.77919299683829, epsilon: 0.270754259511994\n",
            "Episode: 130, total reward: 127.42112814563615, epsilon: 0.26804671691687404\n",
            "Episode: 131, total reward: -12.121439813021352, epsilon: 0.2653662497477053\n",
            "Episode: 132, total reward: 115.15512237126342, epsilon: 0.2627125872502282\n",
            "Episode: 133, total reward: 26.179921536348314, epsilon: 0.2600854613777259\n",
            "Episode: 134, total reward: -101.45790784763088, epsilon: 0.2574846067639487\n",
            "Episode: 135, total reward: 7.205468360873102, epsilon: 0.2549097606963092\n",
            "Episode: 136, total reward: -64.53470122232824, epsilon: 0.2523606630893461\n",
            "Episode: 137, total reward: 6.352815102777072, epsilon: 0.24983705645845267\n",
            "Episode: 138, total reward: -121.31036801863141, epsilon: 0.24733868589386815\n",
            "Episode: 139, total reward: -50.414825273624146, epsilon: 0.24486529903492946\n",
            "Episode: 140, total reward: 81.29361539114257, epsilon: 0.24241664604458016\n",
            "Episode: 141, total reward: 106.15810638204302, epsilon: 0.23999247958413436\n",
            "Episode: 142, total reward: 256.0851580714308, epsilon: 0.23759255478829303\n",
            "Episode: 143, total reward: 54.407030769277924, epsilon: 0.2352166292404101\n",
            "Episode: 144, total reward: -40.69409683991697, epsilon: 0.232864462948006\n",
            "Episode: 145, total reward: 151.10213118624833, epsilon: 0.23053581831852593\n",
            "Episode: 146, total reward: -33.01473592972714, epsilon: 0.22823046013534068\n",
            "Episode: 147, total reward: -94.80338263146145, epsilon: 0.22594815553398728\n",
            "Episode: 148, total reward: 94.22194441179855, epsilon: 0.22368867397864742\n",
            "Episode: 149, total reward: 9.220957116051942, epsilon: 0.22145178723886094\n",
            "Episode: 150, total reward: -220.54491580173044, epsilon: 0.21923726936647234\n",
            "Episode: 151, total reward: 174.1026390292717, epsilon: 0.2170448966728076\n",
            "Episode: 152, total reward: 57.19299939400122, epsilon: 0.21487444770607952\n",
            "Episode: 153, total reward: -4.216703094086753, epsilon: 0.21272570322901874\n",
            "Episode: 154, total reward: 69.89766170869072, epsilon: 0.21059844619672854\n",
            "Episode: 155, total reward: 124.83783401651078, epsilon: 0.20849246173476127\n",
            "Episode: 156, total reward: -105.03205230879757, epsilon: 0.20640753711741366\n",
            "Episode: 157, total reward: 89.62156842907604, epsilon: 0.20434346174623952\n",
            "Episode: 158, total reward: 83.35701508289924, epsilon: 0.20230002712877712\n",
            "Episode: 159, total reward: 10.017523659689843, epsilon: 0.20027702685748935\n",
            "Episode: 160, total reward: -58.42384683343083, epsilon: 0.19827425658891445\n",
            "Episode: 161, total reward: 79.76313352147986, epsilon: 0.1962915140230253\n",
            "Episode: 162, total reward: 38.95507563012494, epsilon: 0.19432859888279505\n",
            "Episode: 163, total reward: -69.26190419034576, epsilon: 0.1923853128939671\n",
            "Episode: 164, total reward: -71.57609994830503, epsilon: 0.19046145976502743\n",
            "Episode: 165, total reward: 223.36335425871727, epsilon: 0.18855684516737714\n",
            "Episode: 166, total reward: 8.972482102676967, epsilon: 0.18667127671570335\n",
            "Episode: 167, total reward: 52.608068766800955, epsilon: 0.18480456394854633\n",
            "Episode: 168, total reward: -16.80931197442156, epsilon: 0.18295651830906087\n",
            "Episode: 169, total reward: 35.56841031109878, epsilon: 0.18112695312597027\n",
            "Episode: 170, total reward: 222.1099856531365, epsilon: 0.17931568359471056\n",
            "Episode: 171, total reward: 41.41312632590964, epsilon: 0.17752252675876345\n",
            "Episode: 172, total reward: -0.8463382344940942, epsilon: 0.17574730149117582\n",
            "Episode: 173, total reward: 34.47138216584393, epsilon: 0.17398982847626407\n",
            "Episode: 174, total reward: 133.3704805215079, epsilon: 0.17224993019150142\n",
            "Episode: 175, total reward: 70.162291455657, epsilon: 0.1705274308895864\n",
            "Episode: 176, total reward: 220.9157404075641, epsilon: 0.16882215658069055\n",
            "Episode: 177, total reward: 112.35029305428145, epsilon: 0.16713393501488363\n",
            "Episode: 178, total reward: -274.5203805895575, epsilon: 0.16546259566473479\n",
            "Episode: 179, total reward: -42.70095521802526, epsilon: 0.16380796970808745\n",
            "Episode: 180, total reward: 18.1876743830706, epsilon: 0.16216989001100657\n",
            "Episode: 181, total reward: -165.07544327257995, epsilon: 0.1605481911108965\n",
            "Episode: 182, total reward: 195.21835317160395, epsilon: 0.15894270919978754\n",
            "Episode: 183, total reward: 212.58580070967383, epsilon: 0.15735328210778965\n",
            "Episode: 184, total reward: -92.1899933178669, epsilon: 0.15577974928671176\n",
            "Episode: 185, total reward: -150.75672227048483, epsilon: 0.15422195179384465\n",
            "Episode: 186, total reward: 156.63631942029798, epsilon: 0.1526797322759062\n",
            "Episode: 187, total reward: -281.2325710252062, epsilon: 0.15115293495314713\n",
            "Episode: 188, total reward: 212.6771570997106, epsilon: 0.14964140560361566\n",
            "Episode: 189, total reward: 90.54780141421327, epsilon: 0.1481449915475795\n",
            "Episode: 190, total reward: -175.6639995546388, epsilon: 0.1466635416321037\n",
            "Episode: 191, total reward: 294.7664712422569, epsilon: 0.14519690621578268\n",
            "Episode: 192, total reward: -191.8817221623774, epsilon: 0.14374493715362485\n",
            "Episode: 193, total reward: 163.31506595795716, epsilon: 0.1423074877820886\n",
            "Episode: 194, total reward: 179.76365077344877, epsilon: 0.1408844129042677\n",
            "Episode: 195, total reward: 225.78309200541125, epsilon: 0.13947556877522502\n",
            "Episode: 196, total reward: 214.23051281723866, epsilon: 0.13808081308747278\n",
            "Episode: 197, total reward: 25.912266360236572, epsilon: 0.13670000495659804\n",
            "Episode: 198, total reward: 162.45728298148663, epsilon: 0.13533300490703207\n",
            "Episode: 199, total reward: -189.5376937487246, epsilon: 0.13397967485796175\n",
            "Episode: 200, total reward: 167.18268303007744, epsilon: 0.13263987810938213\n",
            "Episode: 201, total reward: -305.1317608161992, epsilon: 0.1313134793282883\n",
            "Episode: 202, total reward: 245.88682060372633, epsilon: 0.13000034453500542\n",
            "Episode: 203, total reward: 265.751432207918, epsilon: 0.12870034108965536\n",
            "Episode: 204, total reward: 162.0704631183578, epsilon: 0.12741333767875881\n",
            "Episode: 205, total reward: 270.0337872097747, epsilon: 0.12613920430197123\n",
            "Episode: 206, total reward: 231.42769899686556, epsilon: 0.12487781225895152\n",
            "Episode: 207, total reward: 163.48651664581425, epsilon: 0.123629034136362\n",
            "Episode: 208, total reward: 46.69414337852481, epsilon: 0.12239274379499838\n",
            "Episode: 209, total reward: 233.85475583154565, epsilon: 0.1211688163570484\n",
            "Episode: 210, total reward: -51.592856254375135, epsilon: 0.11995712819347792\n",
            "Episode: 211, total reward: -323.8667620430177, epsilon: 0.11875755691154315\n",
            "Episode: 212, total reward: 238.38153335563015, epsilon: 0.11756998134242772\n",
            "Episode: 213, total reward: -118.13083384815636, epsilon: 0.11639428152900344\n",
            "Episode: 214, total reward: 236.08183001490568, epsilon: 0.11523033871371341\n",
            "Episode: 215, total reward: 287.99582307712603, epsilon: 0.11407803532657627\n",
            "Episode: 216, total reward: 281.6912370821133, epsilon: 0.11293725497331052\n",
            "Episode: 217, total reward: 42.95470587525756, epsilon: 0.1118078824235774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode: 218, total reward: 7.608399092131052, epsilon: 0.11068980359934164\n",
            "Episode: 219, total reward: 9.441399455469607, epsilon: 0.10958290556334822\n",
            "Episode: 220, total reward: 228.08485524851255, epsilon: 0.10848707650771475\n",
            "Episode: 221, total reward: 184.97304286518482, epsilon: 0.1074022057426376\n",
            "Episode: 222, total reward: -33.42620646626666, epsilon: 0.10632818368521123\n",
            "Episode: 223, total reward: 247.45138395289567, epsilon: 0.10526490184835911\n",
            "Episode: 224, total reward: 238.5149393314798, epsilon: 0.10421225282987552\n",
            "Episode: 225, total reward: 291.284175119692, epsilon: 0.10317013030157676\n",
            "Episode: 226, total reward: 11.974402545361315, epsilon: 0.10213842899856099\n",
            "Episode: 227, total reward: -65.0167375349999, epsilon: 0.10111704470857538\n",
            "Episode: 228, total reward: 273.2766359306104, epsilon: 0.10010587426148963\n",
            "Episode: 229, total reward: 31.994697279113964, epsilon: 0.09910481551887473\n",
            "Episode: 230, total reward: -155.7337588470827, epsilon: 0.09811376736368599\n",
            "Episode: 231, total reward: 227.9628097189443, epsilon: 0.09713262969004913\n",
            "Episode: 232, total reward: -4.82540834513986, epsilon: 0.09616130339314863\n",
            "Episode: 233, total reward: 174.75917476211458, epsilon: 0.09519969035921715\n",
            "Episode: 234, total reward: 162.83928624305906, epsilon: 0.09424769345562498\n",
            "Episode: 235, total reward: -40.468772359124, epsilon: 0.09330521652106873\n",
            "Episode: 236, total reward: 258.2598899095417, epsilon: 0.09237216435585804\n",
            "Episode: 237, total reward: 232.39459011479155, epsilon: 0.09144844271229946\n",
            "Episode: 238, total reward: 205.2683656930333, epsilon: 0.09053395828517646\n",
            "Episode: 239, total reward: 206.67217901783627, epsilon: 0.08962861870232469\n",
            "Episode: 240, total reward: 280.5095589995238, epsilon: 0.08873233251530144\n",
            "Episode: 241, total reward: 218.07063034995724, epsilon: 0.08784500919014843\n",
            "Episode: 242, total reward: 185.99752668303265, epsilon: 0.08696655909824694\n",
            "Episode: 243, total reward: -62.24647487376767, epsilon: 0.08609689350726446\n",
            "Episode: 244, total reward: 239.87579446265062, epsilon: 0.08523592457219181\n",
            "Episode: 245, total reward: 267.40313222814433, epsilon: 0.0843835653264699\n",
            "Episode: 246, total reward: 210.83532317669102, epsilon: 0.0835397296732052\n",
            "Episode: 247, total reward: 257.1846757443057, epsilon: 0.08270433237647315\n",
            "Episode: 248, total reward: 225.62334953290224, epsilon: 0.08187728905270841\n",
            "Episode: 249, total reward: 253.4852551872405, epsilon: 0.08105851616218133\n",
            "Episode: 250, total reward: 216.13763163426069, epsilon: 0.08024793100055952\n",
            "Episode: 251, total reward: 174.46142025765346, epsilon: 0.07944545169055392\n",
            "Episode: 252, total reward: 226.22598005678594, epsilon: 0.07865099717364837\n",
            "Episode: 253, total reward: 241.75463805410627, epsilon: 0.07786448720191189\n",
            "Episode: 254, total reward: 247.8633352799267, epsilon: 0.07708584232989277\n",
            "Episode: 255, total reward: 283.56483453762644, epsilon: 0.07631498390659384\n",
            "Episode: 256, total reward: 191.8571334170046, epsilon: 0.07555183406752791\n",
            "Episode: 257, total reward: 250.63035008818403, epsilon: 0.07479631572685264\n",
            "Episode: 258, total reward: 229.38494009212823, epsilon: 0.07404835256958411\n",
            "Episode: 259, total reward: 223.75426915137282, epsilon: 0.07330786904388827\n",
            "Episode: 260, total reward: 223.0165845047229, epsilon: 0.07257479035344938\n",
            "Episode: 261, total reward: 250.8520016238616, epsilon: 0.07184904244991488\n",
            "Episode: 262, total reward: 282.38740753288147, epsilon: 0.07113055202541574\n",
            "Episode: 263, total reward: -17.108718004194287, epsilon: 0.07041924650516158\n",
            "Episode: 264, total reward: 28.522000480111245, epsilon: 0.06971505404010997\n",
            "Episode: 265, total reward: 208.36457528130006, epsilon: 0.06901790349970886\n",
            "Episode: 266, total reward: -63.66438916543005, epsilon: 0.06832772446471178\n",
            "Episode: 267, total reward: 231.4379753928444, epsilon: 0.06764444722006466\n",
            "Episode: 268, total reward: 178.8096910181572, epsilon: 0.066968002747864\n",
            "Episode: 269, total reward: 239.86914319141297, epsilon: 0.06629832272038537\n",
            "Episode: 270, total reward: 244.0732139014237, epsilon: 0.06563533949318151\n",
            "Episode: 271, total reward: 178.35615604755645, epsilon: 0.06497898609824969\n",
            "Episode: 272, total reward: 206.32151499540248, epsilon: 0.0643291962372672\n",
            "Episode: 273, total reward: 225.87341950521204, epsilon: 0.06368590427489453\n",
            "Episode: 274, total reward: 256.51907740488855, epsilon: 0.06304904523214558\n",
            "Episode: 275, total reward: 218.51916363894046, epsilon: 0.06241855477982412\n",
            "Episode: 276, total reward: -192.62630074842787, epsilon: 0.06179436923202588\n",
            "Episode: 277, total reward: 265.8646046318703, epsilon: 0.06117642553970562\n",
            "Episode: 278, total reward: -290.9867887801959, epsilon: 0.06056466128430856\n",
            "Episode: 279, total reward: 148.39064899962827, epsilon: 0.05995901467146548\n",
            "Episode: 280, total reward: 234.16363787920557, epsilon: 0.05935942452475082\n",
            "Episode: 281, total reward: 241.55806674482454, epsilon: 0.058765830279503314\n",
            "Episode: 282, total reward: 227.71475509408106, epsilon: 0.05817817197670828\n",
            "Episode: 283, total reward: 225.17162937909572, epsilon: 0.057596390256941195\n",
            "Episode: 284, total reward: 238.10751158865057, epsilon: 0.05702042635437178\n",
            "Episode: 285, total reward: 270.95658014688934, epsilon: 0.05645022209082806\n",
            "Episode: 286, total reward: 230.3769794339833, epsilon: 0.05588571986991978\n",
            "Episode: 287, total reward: 208.51872861026916, epsilon: 0.055326862671220584\n",
            "Episode: 288, total reward: 244.17066175246282, epsilon: 0.05477359404450838\n",
            "Episode: 289, total reward: 230.18095601733137, epsilon: 0.054225858104063294\n",
            "Episode: 290, total reward: 265.45784789994957, epsilon: 0.05368359952302266\n",
            "Episode: 291, total reward: 205.43929846926585, epsilon: 0.053146763527792434\n",
            "Episode: 292, total reward: 257.4233584595088, epsilon: 0.052615295892514506\n",
            "Episode: 293, total reward: 264.0032099631347, epsilon: 0.052089142933589364\n",
            "Episode: 294, total reward: 246.02165057214643, epsilon: 0.05156825150425347\n",
            "Episode: 295, total reward: 172.57981484402683, epsilon: 0.051052568989210935\n",
            "Episode: 296, total reward: 230.9801937975466, epsilon: 0.05054204329931883\n",
            "Episode: 297, total reward: 260.48995141562017, epsilon: 0.05003662286632564\n",
            "Episode: 298, total reward: 275.5518359840679, epsilon: 0.04953625663766238\n",
            "Episode: 299, total reward: 218.24015195826752, epsilon: 0.04904089407128576\n",
            "Episode: 300, total reward: 263.583199701745, epsilon: 0.0485504851305729\n",
            "Episode: 301, total reward: 231.07533701048504, epsilon: 0.048064980279267165\n",
            "Episode: 302, total reward: 261.58022035113197, epsilon: 0.04758433047647449\n",
            "Episode: 303, total reward: 294.7433889204138, epsilon: 0.04710848717170975\n",
            "Episode: 304, total reward: 250.7686487445755, epsilon: 0.04663740229999265\n",
            "Episode: 305, total reward: 250.66380794186963, epsilon: 0.04617102827699272\n",
            "Episode: 306, total reward: -70.51283215389337, epsilon: 0.045709317994222794\n",
            "Episode: 307, total reward: 292.68268841422935, epsilon: 0.04525222481428057\n",
            "Episode: 308, total reward: 269.71685688042476, epsilon: 0.04479970256613776\n",
            "Episode: 309, total reward: 250.29142776035783, epsilon: 0.04435170554047638\n",
            "Episode: 310, total reward: 246.97469021956047, epsilon: 0.043908188485071616\n",
            "Episode: 311, total reward: 254.6120011464286, epsilon: 0.0434691066002209\n",
            "Episode: 312, total reward: 232.90751422496584, epsilon: 0.04303441553421869\n",
            "Episode: 313, total reward: 251.81863389010815, epsilon: 0.0426040713788765\n",
            "Episode: 314, total reward: 266.453935980968, epsilon: 0.04217803066508773\n",
            "Episode: 315, total reward: 193.81739501972697, epsilon: 0.04175625035843686\n",
            "Episode: 316, total reward: 265.360408265064, epsilon: 0.041338687854852486\n",
            "Episode: 317, total reward: 223.6949138130056, epsilon: 0.04092530097630396\n",
            "Episode: 318, total reward: 246.99962897717666, epsilon: 0.040516047966540916\n",
            "Episode: 319, total reward: 262.8062509832206, epsilon: 0.04011088748687551\n",
            "Episode: 320, total reward: 217.4012603684161, epsilon: 0.03970977861200675\n",
            "Episode: 321, total reward: 240.66296714730754, epsilon: 0.03931268082588668\n",
            "Episode: 322, total reward: 295.9871419630189, epsilon: 0.03891955401762781\n",
            "Episode: 323, total reward: 275.30816669046783, epsilon: 0.03853035847745153\n",
            "Episode: 324, total reward: 290.2354423835902, epsilon: 0.03814505489267701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode: 325, total reward: 285.69064872889254, epsilon: 0.03776360434375024\n",
            "Episode: 326, total reward: 245.47866483161712, epsilon: 0.03738596830031274\n",
            "Episode: 327, total reward: -193.17826148343084, epsilon: 0.03701210861730961\n",
            "Episode: 328, total reward: 254.51806415809892, epsilon: 0.03664198753113651\n",
            "Episode: 329, total reward: 245.28194749597887, epsilon: 0.036275567655825146\n",
            "Episode: 330, total reward: 263.8804541747042, epsilon: 0.03591281197926689\n",
            "Episode: 331, total reward: 279.5238759069143, epsilon: 0.035553683859474224\n",
            "Episode: 332, total reward: 221.56892562029572, epsilon: 0.03519814702087948\n",
            "Episode: 333, total reward: 279.31252943836625, epsilon: 0.03484616555067068\n",
            "Episode: 334, total reward: 237.04890622768855, epsilon: 0.034497703895163975\n",
            "Episode: 335, total reward: 286.46936207158956, epsilon: 0.03415272685621234\n",
            "Episode: 336, total reward: 260.6107296260254, epsilon: 0.03381119958765021\n",
            "Episode: 337, total reward: 279.39177479547845, epsilon: 0.03347308759177371\n",
            "Episode: 338, total reward: 246.04179014477427, epsilon: 0.03313835671585597\n",
            "Episode: 339, total reward: 276.6576329340879, epsilon: 0.03280697314869741\n",
            "Episode: 340, total reward: 304.1584288211583, epsilon: 0.032478903417210436\n",
            "Episode: 341, total reward: 280.6814650693488, epsilon: 0.032154114383038335\n",
            "Episode: 342, total reward: 288.96046365811293, epsilon: 0.03183257323920795\n",
            "Episode: 343, total reward: 274.0122251278973, epsilon: 0.03151424750681587\n",
            "Episode: 344, total reward: 229.47625901151204, epsilon: 0.03119910503174771\n",
            "Episode: 345, total reward: 278.4622956317203, epsilon: 0.030887113981430233\n",
            "Episode: 346, total reward: 240.3904820795634, epsilon: 0.03057824284161593\n",
            "Episode: 347, total reward: 235.4415153171986, epsilon: 0.03027246041319977\n",
            "Episode: 348, total reward: 260.7914830436213, epsilon: 0.029969735809067772\n",
            "Episode: 349, total reward: 236.0773153096106, epsilon: 0.029670038450977095\n",
            "Episode: 350, total reward: 268.5493020868476, epsilon: 0.029373338066467324\n",
            "Episode: 351, total reward: 229.6941462903475, epsilon: 0.02907960468580265\n",
            "Episode: 352, total reward: 276.516440237358, epsilon: 0.028788808638944622\n",
            "Episode: 353, total reward: 266.2808695146201, epsilon: 0.028500920552555174\n",
            "Episode: 354, total reward: 294.7704093561065, epsilon: 0.028215911347029624\n",
            "Episode: 355, total reward: 233.8910404827774, epsilon: 0.027933752233559327\n",
            "Episode: 356, total reward: 266.42711276902384, epsilon: 0.027654414711223735\n",
            "Episode: 357, total reward: 256.76707776191233, epsilon: 0.027377870564111496\n",
            "Episode: 358, total reward: 300.90645998442716, epsilon: 0.027104091858470382\n",
            "Episode: 359, total reward: 254.45748710306012, epsilon: 0.026833050939885677\n",
            "Episode: 360, total reward: 249.84808665777905, epsilon: 0.02656472043048682\n",
            "Episode: 361, total reward: 237.25833104981473, epsilon: 0.02629907322618195\n",
            "Episode: 362, total reward: 231.6146347280663, epsilon: 0.026036082493920133\n",
            "Episode: 363, total reward: 273.8335037137907, epsilon: 0.02577572166898093\n",
            "Episode: 364, total reward: 274.56970245744, epsilon: 0.025517964452291122\n",
            "Episode: 365, total reward: 268.1276214796258, epsilon: 0.02526278480776821\n",
            "Episode: 366, total reward: 289.29840773218046, epsilon: 0.025010156959690527\n",
            "Episode: 367, total reward: 267.60315419932954, epsilon: 0.02476005539009362\n",
            "Episode: 368, total reward: 26.494381686787634, epsilon: 0.024512454836192684\n",
            "Episode: 369, total reward: 263.86228924001387, epsilon: 0.024267330287830756\n",
            "Episode: 370, total reward: 284.1356808731477, epsilon: 0.024024656984952448\n",
            "Episode: 371, total reward: 253.43089132369596, epsilon: 0.023784410415102923\n",
            "Episode: 372, total reward: 260.9676050536121, epsilon: 0.023546566310951894\n",
            "Episode: 373, total reward: 264.760546613939, epsilon: 0.023311100647842375\n",
            "Episode: 374, total reward: 252.0439116255924, epsilon: 0.02307798964136395\n",
            "Episode: 375, total reward: 56.91402470732285, epsilon: 0.022847209744950314\n",
            "Episode: 376, total reward: 266.89249738933427, epsilon: 0.02261873764750081\n",
            "Episode: 377, total reward: 236.71637007104826, epsilon: 0.022392550271025803\n",
            "Episode: 378, total reward: 252.14667069701062, epsilon: 0.022168624768315544\n",
            "Episode: 379, total reward: 239.81442386344963, epsilon: 0.02194693852063239\n",
            "Episode: 380, total reward: 239.53750586447572, epsilon: 0.021727469135426065\n",
            "Episode: 381, total reward: 251.6828553488761, epsilon: 0.021510194444071803\n",
            "Episode: 382, total reward: 258.9648120458137, epsilon: 0.021295092499631085\n",
            "Episode: 383, total reward: 274.86251943074615, epsilon: 0.021082141574634772\n",
            "Episode: 384, total reward: 233.16060779509138, epsilon: 0.020871320158888425\n",
            "Episode: 385, total reward: 267.3355818005742, epsilon: 0.020662606957299542\n",
            "Episode: 386, total reward: 288.8974764661413, epsilon: 0.020455980887726547\n",
            "Episode: 387, total reward: -22.91069364399425, epsilon: 0.02025142107884928\n",
            "Episode: 388, total reward: 277.68745823938883, epsilon: 0.020048906868060788\n",
            "Episode: 389, total reward: 156.46811307803102, epsilon: 0.01984841779938018\n",
            "Episode: 390, total reward: 241.92823553116398, epsilon: 0.019649933621386378\n",
            "Episode: 391, total reward: 262.3743019542403, epsilon: 0.019453434285172513\n",
            "Episode: 392, total reward: 283.12235256611814, epsilon: 0.019258899942320787\n",
            "Episode: 393, total reward: 207.74640216877032, epsilon: 0.01906631094289758\n",
            "Episode: 394, total reward: 236.0795800964054, epsilon: 0.018875647833468602\n",
            "Episode: 395, total reward: 259.92624191080245, epsilon: 0.018686891355133916\n",
            "Episode: 396, total reward: 236.86660724089126, epsilon: 0.018500022441582577\n",
            "Episode: 397, total reward: 259.95273192781457, epsilon: 0.01831502221716675\n",
            "Episode: 398, total reward: 207.33910295061835, epsilon: 0.018131871994995084\n",
            "Episode: 399, total reward: 264.19372337262985, epsilon: 0.017950553275045134\n",
            "Episode: 400, total reward: 168.68666076082587, epsilon: 0.017771047742294682\n",
            "Episode: 401, total reward: 237.49038092391243, epsilon: 0.017593337264871736\n",
            "Episode: 402, total reward: 273.81229803608574, epsilon: 0.01741740389222302\n",
            "Episode: 403, total reward: 249.86706147396487, epsilon: 0.01724322985330079\n",
            "Episode: 404, total reward: -38.774581196144155, epsilon: 0.017070797554767782\n",
            "Episode: 405, total reward: 281.3280987818096, epsilon: 0.016900089579220106\n",
            "Episode: 406, total reward: 244.3200376558777, epsilon: 0.016731088683427906\n",
            "Episode: 407, total reward: 257.47312522668443, epsilon: 0.016563777796593626\n",
            "Episode: 408, total reward: 192.5624763871936, epsilon: 0.016398140018627688\n",
            "Episode: 409, total reward: 238.72472054049848, epsilon: 0.01623415861844141\n",
            "Episode: 410, total reward: 248.552662472484, epsilon: 0.016071817032256998\n",
            "Episode: 411, total reward: 229.18545248191649, epsilon: 0.01591109886193443\n",
            "Episode: 412, total reward: 252.45288042071473, epsilon: 0.015751987873315085\n",
            "Episode: 413, total reward: 258.65783208774087, epsilon: 0.015594467994581935\n",
            "Episode: 414, total reward: 267.95790308384625, epsilon: 0.015438523314636115\n",
            "Episode: 415, total reward: 257.7726839260333, epsilon: 0.015284138081489753\n",
            "Episode: 416, total reward: 265.0101808956989, epsilon: 0.015131296700674856\n",
            "Episode: 417, total reward: 247.6997929849579, epsilon: 0.014979983733668108\n",
            "Episode: 418, total reward: 228.60488945980796, epsilon: 0.014830183896331426\n",
            "Episode: 419, total reward: -119.47104753762905, epsilon: 0.014681882057368112\n",
            "Episode: 420, total reward: 238.771089704156, epsilon: 0.01453506323679443\n",
            "Episode: 421, total reward: 215.6380544305517, epsilon: 0.014389712604426485\n",
            "Episode: 422, total reward: 297.49247356258184, epsilon: 0.01424581547838222\n",
            "Episode: 423, total reward: 25.99942797240368, epsilon: 0.014103357323598397\n",
            "Episode: 424, total reward: 231.21692471813836, epsilon: 0.013962323750362413\n",
            "Episode: 425, total reward: 282.888284739833, epsilon: 0.013822700512858789\n",
            "Episode: 426, total reward: 255.70580314517633, epsilon: 0.0136844735077302\n",
            "Episode: 427, total reward: 250.5217254772602, epsilon: 0.013547628772652899\n",
            "Episode: 428, total reward: 268.2086774003047, epsilon: 0.01341215248492637\n",
            "Episode: 429, total reward: 277.6796617028534, epsilon: 0.013278030960077106\n",
            "Episode: 430, total reward: 263.16620635272807, epsilon: 0.013145250650476335\n",
            "Episode: 431, total reward: 256.1137550973525, epsilon: 0.01301379814397157\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Episode: 432, total reward: 292.83711632650284, epsilon: 0.012883660162531854\n",
            "Episode: 433, total reward: 235.3314071483988, epsilon: 0.012754823560906535\n",
            "Episode: 434, total reward: 256.2395448559487, epsilon: 0.01262727532529747\n",
            "Episode: 435, total reward: 251.65002897333684, epsilon: 0.012501002572044496\n",
            "Episode: 436, total reward: 282.5867519373984, epsilon: 0.01237599254632405\n",
            "Episode: 437, total reward: 247.78149511912275, epsilon: 0.01225223262086081\n",
            "Episode: 438, total reward: 260.1196458917367, epsilon: 0.012129710294652202\n",
            "Episode: 439, total reward: 260.84514256821717, epsilon: 0.01200841319170568\n",
            "Episode: 440, total reward: 208.89856569659375, epsilon: 0.011888329059788623\n",
            "Episode: 441, total reward: 251.1282091477819, epsilon: 0.011769445769190737\n",
            "Episode: 442, total reward: 277.4974222767653, epsilon: 0.01165175131149883\n",
            "Episode: 443, total reward: 279.4277164707501, epsilon: 0.011535233798383842\n",
            "Episode: 444, total reward: -229.0454436448509, epsilon: 0.011419881460400004\n",
            "Episode: 445, total reward: 246.4938390843819, epsilon: 0.011305682645796004\n",
            "Episode: 446, total reward: 269.35871724371646, epsilon: 0.011192625819338045\n",
            "Episode: 447, total reward: 271.5253788310865, epsilon: 0.011080699561144665\n",
            "Episode: 448, total reward: 254.69038215930806, epsilon: 0.010969892565533218\n",
            "Episode: 449, total reward: 255.26103686168017, epsilon: 0.010860193639877886\n",
            "Episode: 450, total reward: 295.406663996553, epsilon: 0.010751591703479106\n",
            "Episode: 451, total reward: 258.0034660936391, epsilon: 0.010644075786444315\n",
            "Episode: 452, total reward: 249.26463555484565, epsilon: 0.010537635028579873\n",
            "Episode: 453, total reward: 217.87108469681715, epsilon: 0.010432258678294073\n",
            "Episode: 454, total reward: 200.85781004385834, epsilon: 0.010327936091511133\n",
            "Episode: 455, total reward: 255.12412266104008, epsilon: 0.010224656730596022\n",
            "Episode: 456, total reward: 231.07675360009785, epsilon: 0.01012241016329006\n",
            "Episode: 457, total reward: 265.4736601386624, epsilon: 0.01002118606165716\n",
            "Episode: 458, total reward: 269.67821440233797, epsilon: 0.01\n",
            "Episode: 459, total reward: 270.8146064088937, epsilon: 0.01\n",
            "Episode: 460, total reward: 306.1206721777464, epsilon: 0.01\n",
            "Episode: 461, total reward: 279.1605956086919, epsilon: 0.01\n",
            "Episode: 462, total reward: 268.3857862151149, epsilon: 0.01\n",
            "Episode: 463, total reward: 243.76050569765937, epsilon: 0.01\n",
            "Episode: 464, total reward: 242.8757298118371, epsilon: 0.01\n",
            "Episode: 465, total reward: 301.2016870663241, epsilon: 0.01\n",
            "Episode: 466, total reward: 258.11039802471043, epsilon: 0.01\n",
            "Episode: 467, total reward: 258.0219476992496, epsilon: 0.01\n",
            "Episode: 468, total reward: 296.80890878269577, epsilon: 0.01\n",
            "Episode: 469, total reward: 265.93823021344053, epsilon: 0.01\n",
            "Episode: 470, total reward: 259.7521367744588, epsilon: 0.01\n",
            "Episode: 471, total reward: 252.98236644899578, epsilon: 0.01\n",
            "Episode: 472, total reward: 248.27753325864956, epsilon: 0.01\n",
            "Episode: 473, total reward: 261.01611346925245, epsilon: 0.01\n",
            "Episode: 474, total reward: 232.85010100242502, epsilon: 0.01\n",
            "Episode: 475, total reward: 254.55464446839457, epsilon: 0.01\n",
            "Episode: 476, total reward: 271.7831853372761, epsilon: 0.01\n",
            "Episode: 477, total reward: 244.6221553119393, epsilon: 0.01\n",
            "Episode: 478, total reward: 219.53549800163154, epsilon: 0.01\n",
            "Episode: 479, total reward: 272.64221631364956, epsilon: 0.01\n",
            "Episode: 480, total reward: 242.32606936880234, epsilon: 0.01\n",
            "Episode: 481, total reward: 231.92642414955088, epsilon: 0.01\n",
            "Episode: 482, total reward: 276.6508272807346, epsilon: 0.01\n",
            "Episode: 483, total reward: 281.87500171566927, epsilon: 0.01\n",
            "Episode: 484, total reward: 273.21894179172455, epsilon: 0.01\n",
            "Episode: 485, total reward: 278.16095859890544, epsilon: 0.01\n",
            "Episode: 486, total reward: 266.7587338951323, epsilon: 0.01\n",
            "Episode: 487, total reward: 253.9807375541103, epsilon: 0.01\n",
            "Episode: 488, total reward: 275.5350852823379, epsilon: 0.01\n",
            "Episode: 489, total reward: 265.6217805030024, epsilon: 0.01\n",
            "Episode: 490, total reward: 256.80287936678485, epsilon: 0.01\n",
            "Episode: 491, total reward: 255.381201789181, epsilon: 0.01\n",
            "Episode: 492, total reward: 296.6895356055095, epsilon: 0.01\n",
            "Episode: 493, total reward: 306.0171677649415, epsilon: 0.01\n",
            "Episode: 494, total reward: 302.12692456273766, epsilon: 0.01\n",
            "Episode: 495, total reward: 275.4475270169578, epsilon: 0.01\n",
            "Episode: 496, total reward: 295.9571419430454, epsilon: 0.01\n",
            "Episode: 497, total reward: 257.74485904243346, epsilon: 0.01\n",
            "Episode: 498, total reward: 305.1925557371201, epsilon: 0.01\n",
            "Episode: 499, total reward: -13.372360381014218, epsilon: 0.01\n",
            "Total time: 19.424482261472278 hours\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-7A5lp7W_T6",
        "outputId": "b7ccf264-dd69-4c5b-cb3f-6fc9fed231e7"
      },
      "source": [
        "N = len(total_rewards)\n",
        "running_avg = np.empty(N)\n",
        "for t in range(N):\n",
        "    running_avg[t] = np.mean(total_rewards[max(0, t-20):(t+1)])\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Score')\n",
        "plt.scatter(x, running_avg, color=\"steelblue\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJK5P1sXW_T7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}